{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa99d8bc",
   "metadata": {},
   "source": [
    "Down Sample with ICN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c780d2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4291863372.py, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 59\u001b[0;36m\u001b[0m\n\u001b[0;31m    def load_model(model_path input_size):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time \n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import k3d\n",
    "import fpsample\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "from model_path import get_model_paths\n",
    "\n",
    "#add path to utils\n",
    "sys.path.append('../')\n",
    "from utils.grid_histogram_overlap import get_intensity_histogram\n",
    "from utils.intensity_correlation_network import ICN\n",
    "from utils.visualize import visualize_pcd, histogram_based_pcd, one_histogram_based_pcd, plot_histograms\n",
    "\n",
    "def get_device():\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_ply(filename):\n",
    "    #.plyファイルを読み込み　点群(x, y, z, intensity)のnumpy配列を返す\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            header_index = None\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'end_header' in line:\n",
    "                    header_index = i\n",
    "                    break\n",
    "            if header_index is None:\n",
    "                raise ValueError(\"PLYファイルのヘッダが正しく読み込めませんでした。\")\n",
    "            \n",
    "            # ヘッダ以降の行を読み込み\n",
    "            points = np.array([list(map(float, l.split())) for l in lines[header_index+1:]])\n",
    "            if points.shape[1] < 4:\n",
    "                # xyz + intensity(もしくは他の属性)がなければエラー\n",
    "                raise ValueError(f\"期待される列数に満たないデータが検出されました: {points.shape[1]}列\")\n",
    "            \n",
    "            # [x, y, z, intensity] の形に整形\n",
    "            # intensity が最後の列にあると仮定 (points[:, -1])\n",
    "            points = np.concatenate([points[:, :3], points[:, -1].reshape(-1, 1)], axis=1)\n",
    "            \n",
    "            return points\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ファイルが見つかりません: {filename}\")\n",
    "        # 必要に応じて sys.exit(1) などで終了するか、Noneを返す\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"PLYファイルの読み込みエラー: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"予期せぬエラーが発生しました（load_ply）: {e}\")\n",
    "        return None\n",
    "    \n",
    "def cos_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def load_model(model_path, input_size):\n",
    "    \"\"\"\n",
    "    モデルをロードする。\n",
    "    エラー処理を挟んで、ロード失敗時には None を返す。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = ICN(input_size=input_size)\n",
    "        # デバイスオフロード対応\n",
    "        device = get_device()\n",
    "        # map_location を追加して、GPUがなければCPUに落とす\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        return model\n",
    "    except FileNotFoundError:\n",
    "        print(f\"モデルファイルが見つかりません: {model_path}\")\n",
    "        return None\n",
    "    except RuntimeError as e:\n",
    "        print(f\"モデルのロードに失敗しました: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"予期せぬエラーが発生しました(load_model): {e}\")\n",
    "        return None\n",
    "    \n",
    "def apply_weights(matrix, threshold = 0.9, weight = 1.5):\n",
    "    weighted_matrix = np.copy(matrix)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            if matrix[i, j] >= threshold:\n",
    "                for di in range(-1, 2):\n",
    "                    for dj in range(-1, 2):\n",
    "                        ni, nj = i + di, j + dj\n",
    "                        if 0 <= ni < matrix.shape[0] and 0 <= nj < matrix.shape[1] and (di != 0 or dj != 0):\n",
    "                            weighted_matrix[ni, nj] = matrix[ni, nj] * weight\n",
    "    return weighted_matrix\n",
    "\n",
    "def find_max_kernel(matrix, kernel_size):\n",
    "    kernel = np.ones((kernel_size, kernel_size), dtype=np.float32)\n",
    "    convolved = convolve2d(matrix, kernel, mode='valid')\n",
    "    max_sum = np.max(convolved)\n",
    "    max_index = np.unravel_index(np.argmax(convolved), convolved.shape)\n",
    "    max_indices = [(max_index[0] + ki, max_index[1] + kj)\n",
    "                   for ki in range(kernel_size)\n",
    "                   for kj in range(kernel_size)]\n",
    "    return max_sum, max_indices\n",
    "\n",
    "def compute_histograms(src_pcd, tgt_pcd, grid_size, threshold, bin_num, overlap):\n",
    "    \"\"\"\n",
    "    src_pcd, tgt_pcd は torch.Tensor で GPU上にあっても構わないが、\n",
    "    get_intensity_histogram は基本的に NumPy を想定している場合があるので、\n",
    "    .cpu().numpy() する等の対応が必要かもしれない。\n",
    "    \"\"\"\n",
    "    # GPU -> CPU -> NumPy\n",
    "    #src_pcd_np = src_pcd.cpu().numpy() if isinstance(src_pcd, torch.Tensor) else src_pcd\n",
    "    #tgt_pcd_np = tgt_pcd.cpu().numpy() if isinstance(tgt_pcd, torch.Tensor) else tgt_pcd\n",
    "    \n",
    "    try:\n",
    "        src_hist, src_bin, step_x1, step_y1, window_size_x1, window_size_y1, window_coords1 = get_intensity_histogram(\n",
    "            src_pcd, grid_size, threshold, bin_num, overlap\n",
    "        )\n",
    "        tgt_hist, tgt_bin, step_x2, step_y2, window_size_x2, window_size_y2, window_coords2 = get_intensity_histogram(\n",
    "            tgt_pcd, grid_size, threshold, bin_num, overlap\n",
    "        )\n",
    "\n",
    "        # Precompute window points count for each grid cell\n",
    "        src_window_points = [\n",
    "            src_pcd[\n",
    "                (src_pcd[:, 0] >= x_start) & (src_pcd[:, 0] < x_end) &\n",
    "                (src_pcd[:, 1] >= y_start) & (src_pcd[:, 1] < y_end)\n",
    "            ].shape[0]\n",
    "            for x_start, x_end, y_start, y_end in window_coords1\n",
    "        ]\n",
    "\n",
    "        tgt_window_points = [\n",
    "            tgt_pcd[\n",
    "                (tgt_pcd[:, 0] >= x_start) & (tgt_pcd[:, 0] < x_end) &\n",
    "                (tgt_pcd[:, 1] >= y_start) & (tgt_pcd[:, 1] < y_end)\n",
    "            ].shape[0]\n",
    "            for x_start, x_end, y_start, y_end in window_coords2\n",
    "        ]\n",
    "\n",
    "        return (src_hist, tgt_hist, src_bin, tgt_bin,\n",
    "                window_coords1, window_coords2, src_window_points, tgt_window_points)\n",
    "    except Exception as e:\n",
    "        print(f\"ヒストグラム計算中にエラーが発生しました: {e}\")\n",
    "        return None, None, None, None, None, None, None, None\n",
    "    \n",
    "def compute_correlations(src_hist, tgt_hist, model, grid_size, border, device, src_window_points, tgt_window_points):\n",
    "    \"\"\"\n",
    "    相関計算を行う。model が None の場合は None を返す。\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"モデルがロードされていません。compute_correlationsをスキップします。\")\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        result_matrix_1 = np.zeros((grid_size, grid_size))\n",
    "        result_matrix_2 = np.zeros((grid_size, grid_size))\n",
    "        result_list = []\n",
    "        used_indices_src_hist = set()\n",
    "        used_indices_tgt_hist = set()\n",
    "\n",
    "        for idx, i in enumerate(src_hist):\n",
    "            if idx in used_indices_src_hist:\n",
    "                continue\n",
    "\n",
    "            max_output = float('-inf')\n",
    "            max_idy = None\n",
    "\n",
    "            for idy, j in enumerate(tgt_hist):\n",
    "                if idy in used_indices_tgt_hist:\n",
    "                    continue\n",
    "\n",
    "                hist_1_tensor = torch.tensor(i, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                hist_2_tensor = torch.tensor(j, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "                hist_1_points = src_window_points[idx]\n",
    "                hist_2_points = tgt_window_points[idy]\n",
    "\n",
    "                # 窓のポイント数の差を考慮して重みをかける\n",
    "                diff_points = min(hist_1_points, hist_2_points) / np.abs(hist_1_points - hist_2_points) + 1e-6\n",
    "                if diff_points >= 1:\n",
    "                    diff_points = 1\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = model(hist_1_tensor, hist_2_tensor)\n",
    "                    output *= diff_points\n",
    "                    predicted = (output > border).float()\n",
    "                    if output > max_output and predicted == 1:\n",
    "                        max_output = output.item()\n",
    "                        max_idy = idy\n",
    "\n",
    "            if max_idy is not None:\n",
    "                y1, x1 = divmod(idx, grid_size)\n",
    "                y2, x2 = divmod(max_idy, grid_size)\n",
    "                result_matrix_1[y1, x1] = max_output\n",
    "                result_matrix_2[y2, x2] = max_output\n",
    "                result_list.append((idx, max_idy, max_output))\n",
    "\n",
    "                used_indices_src_hist.add(idx)\n",
    "                used_indices_tgt_hist.add(max_idy)\n",
    "\n",
    "        return result_matrix_1, result_matrix_2, result_list\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPUメモリエラー等が発生した可能性があります: {e}\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"予期せぬエラーが発生しました（compute_correlations）: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "def process_point_clouds(src_pcd, tgt_pcd, model_path, grid_size, threshold, bin_num, overlap, border):\n",
    "    \"\"\"\n",
    "    メインの処理を行う関数。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        device = get_device()\n",
    "\n",
    "        # pcd が None の場合はエラーを返す\n",
    "        if src_pcd is None or tgt_pcd is None:\n",
    "            print(\"ソースまたはターゲットの点群データが存在しないため、処理を中断します。\")\n",
    "            return None, None, None, None, None, None, None, None, None\n",
    "        \n",
    "        # pytorch Tensor化 & デバイス移行\n",
    "        if not isinstance(src_pcd, torch.Tensor):\n",
    "            src_pcd = torch.from_numpy(src_pcd)\n",
    "        if not isinstance(tgt_pcd, torch.Tensor):\n",
    "            tgt_pcd = torch.from_numpy(tgt_pcd)\n",
    "        src_pcd = src_pcd.to(device)\n",
    "        tgt_pcd = tgt_pcd.to(device)\n",
    "\n",
    "        # ヒストグラム計算\n",
    "        (src_hist, tgt_hist, src_bin, tgt_bin,\n",
    "         window_coords1, window_coords2, \n",
    "         src_window_points, tgt_window_points) = compute_histograms(\n",
    "            src_pcd, tgt_pcd, grid_size, threshold, bin_num, overlap\n",
    "        )\n",
    "\n",
    "        # compute_histogramsが失敗した場合\n",
    "        if src_hist is None or tgt_hist is None:\n",
    "            print(\"ヒストグラム計算に失敗したため、以降の処理を中断します。\")\n",
    "            return None, None, None, None, None, None, None, None, None\n",
    "\n",
    "        # モデル読み込み\n",
    "        model = load_model(model_path, src_hist.shape[1])\n",
    "        if model is None:\n",
    "            print(\"モデルのロードに失敗したため、処理を中断します。\")\n",
    "            return None, None, None, None, None, None, None, None, None\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 相関計算\n",
    "        result_matrix_1, result_matrix_2, result_list = compute_correlations(\n",
    "            src_hist, tgt_hist, model, grid_size, border, device, src_window_points, tgt_window_points\n",
    "        )\n",
    "        if result_matrix_1 is None or result_matrix_2 is None:\n",
    "            print(\"相関計算に失敗したため、処理を中断します。\")\n",
    "            return None, None, None, None, None, None, None, None, None\n",
    "\n",
    "        # 加重\n",
    "        src_weighted_matrix = apply_weights(result_matrix_1)\n",
    "        tgt_weighted_matrix = apply_weights(result_matrix_2)\n",
    "\n",
    "        kernel_size = math.ceil(grid_size / 2)\n",
    "        src_max_sum, src_max_indices = find_max_kernel(src_weighted_matrix, kernel_size)\n",
    "        tgt_max_sum, tgt_max_indices = find_max_kernel(tgt_weighted_matrix, kernel_size)\n",
    "\n",
    "        src_max_indices = [y * grid_size + x for y, x in src_max_indices]\n",
    "        tgt_max_indices = [y * grid_size + x for y, x in tgt_max_indices]\n",
    "\n",
    "        src_icn = histogram_based_pcd(src_pcd, window_coords1, src_max_indices)\n",
    "        tgt_icn = histogram_based_pcd(tgt_pcd, window_coords2, tgt_max_indices)\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Processing time for correlations and downsampling: {processing_time:.3f} seconds\")\n",
    "\n",
    "        return (src_icn, tgt_icn,\n",
    "                src_hist, tgt_hist, \n",
    "                src_bin, tgt_bin, \n",
    "                result_list,\n",
    "                window_coords1, window_coords2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"予期せぬエラーが発生しました（process_point_clouds）: {e}\")\n",
    "        return None, None, None, None, None, None, None, None, None\n",
    "\n",
    "def visualize_and_save_results(src_icn, tgt_icn, result_list, src_pcd, tgt_pcd, \n",
    "                               src_hist, tgt_hist, src_bin, tgt_bin, \n",
    "                               window_coords1, window_coords2):\n",
    "    \"\"\"\n",
    "    結果の可視化と保存を行う。\n",
    "    \"\"\"\n",
    "    # いずれかが None の場合は可視化・保存をスキップ\n",
    "    if src_icn is None or tgt_icn is None or result_list is None:\n",
    "        print(\"可視化・保存対象データが None のためスキップします。\")\n",
    "        return\n",
    "\n",
    "    # 可視化部分\n",
    "    try:\n",
    "        visualize_pcd(src_icn, tgt_icn)\n",
    "        for corr_hist in result_list:\n",
    "            corr_hist = list(corr_hist)\n",
    "            idx_src = corr_hist[0]\n",
    "            idx_tgt = corr_hist[1]\n",
    "\n",
    "            print(corr_hist)\n",
    "            hist1 = one_histogram_based_pcd(src_pcd, window_coords1, idx_src)\n",
    "            hist2 = one_histogram_based_pcd(tgt_pcd, window_coords2, idx_tgt)\n",
    "            print(f\"window {idx_src} shape: {hist1.shape}\")\n",
    "            print(f\"window {idx_tgt} shape: {hist2.shape}\")\n",
    "            print(f\"ICN: {corr_hist[2]:.3f}\")\n",
    "            print(f'Cosine similarity: {cos_similarity(src_hist[idx_src], tgt_hist[idx_tgt]):.3f}')\n",
    "\n",
    "            visualize_pcd(hist1, hist2)\n",
    "            plot_histograms(bin_list=src_bin, hist_list=src_hist, idx=idx_src, title='Histogram 1')\n",
    "            plot_histograms(bin_list=tgt_bin, hist_list=tgt_hist, idx=idx_tgt, title='Histogram 2')\n",
    "\n",
    "        # 保存\n",
    "        save_pcd('../ply/src_icn.ply', src_icn)\n",
    "        save_pcd('../ply/tgt_icn.ply', tgt_icn)\n",
    "    except Exception as e:\n",
    "        print(f\"可視化・保存処理中にエラーが発生しました: {e}\")\n",
    "\n",
    "def save_pcd(filename, pcd):\n",
    "    \"\"\"\n",
    "    点群データを .ply として保存\n",
    "    \"\"\"\n",
    "    # Noneチェック\n",
    "    if pcd is None:\n",
    "        print(f\"保存対象が None のためスキップします: {filename}\")\n",
    "        return\n",
    "\n",
    "    # Torch Tensor の場合は .cpu().numpy()\n",
    "    pcd_np = pcd.cpu().numpy() if isinstance(pcd, torch.Tensor) else pcd\n",
    "    try:\n",
    "        point_cloud = o3d.geometry.PointCloud()\n",
    "        point_cloud.points = o3d.utility.Vector3dVector(pcd_np[:, :3])\n",
    "        o3d.io.write_point_cloud(filename, point_cloud, write_ascii=True)\n",
    "    except Exception as e:\n",
    "        print(f\"点群ファイル {filename} の保存時にエラー: {e}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 実際のスクリプト実行部\n",
    "# -----------------------------\n",
    "# 例: \n",
    "src_file = '../ply/lab1.ply'\n",
    "tgt_file = '../ply/lab2.ply'\n",
    "grid_size = 7\n",
    "overlap = 0.5\n",
    "threshold = 100\n",
    "bin_num = 64\n",
    "border = 0.6\n",
    "\n",
    "# ファイル読み込み\n",
    "src_data = load_ply(src_file)\n",
    "tgt_data = load_ply(tgt_file)\n",
    "\n",
    "if src_data is None or tgt_data is None:\n",
    "    print(\"点群ファイルが正しく読み込めなかったため、終了します。\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# モデルパス取得\n",
    "try:\n",
    "    model_paths = get_model_paths('variation5')\n",
    "    # この辞書アクセスが失敗するかもしれないので try-except\n",
    "    model_path = model_paths[(grid_size, bin_num)]\n",
    "except KeyError:\n",
    "    print(f\"model_paths に指定のキー (grid_size={grid_size}, bin_num={bin_num}) がありません。\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"model_paths 取得時にエラーが発生しました: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# メイン処理\n",
    "(src_icn, tgt_icn,\n",
    "    src_hist, tgt_hist,\n",
    "    src_bin, tgt_bin,\n",
    "    result_list,\n",
    "    window_coords1, window_coords2) = process_point_clouds(\n",
    "    src_data, tgt_data, model_path, grid_size, threshold, bin_num, overlap, border\n",
    ")\n",
    "\n",
    "if src_icn is None:\n",
    "    print(\"処理が中断されたため、終了します。\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 入力点群の可視化（型変換の警告が出る場合は適切にキャストする）\n",
    "print(\"input point cloud:\")\n",
    "try:\n",
    "    # np.float32に変換して警告を抑制(必要に応じて)\n",
    "    src_pcd_for_vis = src_data.astype(np.float32) if src_data is not None else None\n",
    "    tgt_pcd_for_vis = tgt_data.astype(np.float32) if tgt_data is not None else None\n",
    "    visualize_pcd(src_pcd_for_vis, tgt_pcd_for_vis)\n",
    "except Exception as e:\n",
    "    print(f\"点群可視化中にエラーが発生しました: {e}\")\n",
    "\n",
    "print(\"Histograms:\")\n",
    "print(src_hist.shape, tgt_hist.shape)\n",
    "print(\"Correlation results from src_hist to tgt_hist:\")\n",
    "print(result_list)\n",
    "# Print sub point cloud shapes\n",
    "print('Source ICN downsampled shape:', src_icn.shape)\n",
    "print('Target ICN downsampled shape:', tgt_icn.shape)\n",
    "\n",
    "# 可視化 & 保存処理\n",
    "visualize_and_save_results(\n",
    "    src_icn, tgt_icn, result_list, \n",
    "    torch.from_numpy(src_data),  # visualize用に Tensor化する\n",
    "    torch.from_numpy(tgt_data), \n",
    "    src_hist, tgt_hist, \n",
    "    src_bin, tgt_bin, \n",
    "    window_coords1, window_coords2\n",
    ")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3facb005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
